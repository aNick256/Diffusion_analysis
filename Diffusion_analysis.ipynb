directories = []
directory_names = [] #use this to label the columns in the csv files
max_lag_time = 50
segment_duration =max_lag_time
min_fit_points=10
max_fit_points=max_lag_time
do_plot = False


def calculate_msd_1d(positions):
    n = len(positions)
    msd = np.zeros((n, 2))
    
    for i in range(n):
        for j in range(i + 1, n):
            dt = j - i
            msd[dt, 0] += (positions[i] - positions[j])**2
            msd[dt, 1] += 1
    
    return np.divide(
        msd[:, 0],
        msd[:, 1],
        out=np.zeros_like(msd[:, 0]),
        where=msd[:, 1] != 0
    )

def visualize_msd_fit(msd, lag_times, D, alpha, fit_end_index,d_name):
    """
    Visualize the MSD data, the fitted region, and the fitting line.
    
    Parameters:
    msd : array_like
        Mean Square Displacement values
    lag_times : array_like
        Corresponding lag times
    D : float
        Generalized diffusion coefficient
    alpha : float
        Diffusion exponent
    fit_end_index : int
        Index of the last point used in the fit
    """
    plt.figure(figsize=(10, 6))
    
    # Plot full MSD data
    plt.loglog(lag_times, msd, 'o', label='MSD data', markersize=4)
    
    # Highlight fitted region
    plt.loglog(lag_times[:fit_end_index], msd[:fit_end_index], 'o', label='Fitted region', markersize=4)
    
    # Plot fitting line
    fit_line = 2 * D * lag_times**alpha
    plt.loglog(lag_times, fit_line, 'r-', label='Fit: MSD = 2D * t^α '+ d_name)
    
    plt.xlabel('Lag time')
    plt.ylabel('Mean Square Displacement')
    plt.title('MSD Fitting for Diffusion Coefficient Calculation')
    plt.legend()
    
    # Add text with fit results
    plt.text(0.05, 0.05, f'D = {D:.2e}\nα = {alpha:.2f}', transform=plt.gca().transAxes,
             bbox=dict(facecolor='white', edgecolor='gray', alpha=0.8))
    
    plt.grid(True, which="both", ls="-", alpha=0.2)
    plt.tight_layout()
    plt.show()



def calculate_diffusion_coefficient(msd, lag_times, max_fit_points=20):
    """
    Calculate generalized diffusion coefficient and diffusion exponent from MSD data using log-log scale.
    Fits only the initial linear section of the log-log plot.
    
    Parameters:
        msd (array-like): Mean squared displacement data.
        lag_times (array-like): Corresponding lag times for the MSD data.
        max_fit_points (int): Maximum number of points to fit in the initial linear region.
        min_fit_points (int): Minimum number of points required to perform the fit.
        
    Returns:
        generalized_diffusion_coeff (float): Calculated generalized diffusion coefficient.
        diffusion_exponent (float): Calculated diffusion exponent.
        best_end_index (int): The number of points used for the best fit.
    """
    # Remove any zero or negative values to avoid log issues
    valid_indices = (msd > 0) & (lag_times > 0)
    log_msd = np.log(msd[valid_indices])
    log_lag_times = np.log(lag_times[valid_indices])
    

    # Check if there are enough valid points to fit
    if len(log_msd) < min_fit_points:
        return np.nan, np.nan, 0

    # Function to calculate R-squared
    def r_squared(x, y, slope, intercept):
        y_pred = slope * x + intercept
        ss_tot = np.sum((y - np.mean(y))**2)
        ss_res = np.sum((y - y_pred)**2)
        return 1 - (ss_res / ss_tot)

    # Determine the linear region
    if max_fit_points is None:
        max_fit_points = len(log_msd)

    best_r_squared = 0
    best_end_index = 0

    # Find the best fit segment between min_fit_points and max_fit_points
    for end_index in range(min_fit_points, min(len(log_msd), max_fit_points + 1)):
        slope, intercept, _, _, _ = stats.linregress(log_lag_times[:end_index], log_msd[:end_index])
        current_r_squared = r_squared(log_lag_times[:end_index], log_msd[:end_index], slope, intercept)

        if current_r_squared > best_r_squared:
            best_r_squared = current_r_squared
            best_end_index = end_index
        elif current_r_squared < best_r_squared - 0.05:  # Allow for some fluctuation
            break

    # Perform linear regression on the determined linear region
    if best_end_index >= min_fit_points:
        slope, intercept, _, _, _ = stats.linregress(log_lag_times[:best_end_index], log_msd[:best_end_index])
    else:
        return np.nan, np.nan, 0

    # Diffusion exponent is directly the slope
    diffusion_exponent = slope

    # Generalized diffusion coefficient is the exponential of the intercept divided by 2
    # Assuming a 1D system for this implementation
    generalized_diffusion_coeff = np.exp(intercept) / 2

    print(f"Fitted {best_end_index} points. R-squared: {best_r_squared:.4f}")
    print(f"Generalized diffusion coefficient: {generalized_diffusion_coeff:.4e}")
    print(f"Diffusion exponent: {diffusion_exponent:.4f}")

    return generalized_diffusion_coeff, diffusion_exponent, best_end_index


def analyze_csv(file_path, max_lag_time, segment_duration, d_name):
    """Analyze a single CSV file to calculate the MSD and diffusion coefficient."""
    encoding='utf-8'
    data = pd.read_csv(file_path, encoding=encoding)

    if 'X' not in data.columns or 'Y' not in data.columns:
        print(f"Required columns not found in {file_path}")
        return None, None, None

    position_column = 'X'
    time_column = 'Y'

    # Ensure time is in seconds and sorted
    data[time_column] = pd.to_numeric(data[time_column], errors='coerce')
    data = data.sort_values(by=time_column).reset_index(drop=True)

    start_time = data[time_column].min()
    data['time_seconds'] = data[time_column] - start_time

    total_duration = data['time_seconds'].max()
    num_full_segments = int(total_duration // segment_duration)

    segments = []

    for i in range(num_full_segments):
        segment_start = i * segment_duration
        segment_end = (i + 1) * segment_duration
        segment = data[(data['time_seconds'] >= segment_start) & (data['time_seconds'] < segment_end)]

        if len(segment) > 1:
            positions = segment[position_column].values
            times = segment['time_seconds'].values - segment_start

            # Calculate MSD for this segment
            msd_values = calculate_msd_1d(positions)

            # Trim MSD values to max_lag_time if necessary
            msd_values = msd_values[:min(max_lag_time, len(msd_values))]

            segments.append(msd_values)

    if segments:
        # Pad shorter segments with NaN values to ensure equal length
        max_len = max(len(seg) for seg in segments)
        mean_msd_segments = np.array([np.pad(seg, (0, max_len - len(seg)), constant_values=np.nan) for seg in segments])
        
        # Calculate average MSD across all segments, ignoring NaNs
        avg_msd = np.nanmean(mean_msd_segments, axis=0)
        
        # Calculate lag times
        avg_time_step = segment_duration / len(avg_msd)  # Average time step within a segment
        lag_times = np.arange(len(avg_msd)) * avg_time_step
        
        print(f"Length of avg_msd: {len(avg_msd)}, Length of lag_times: {len(lag_times)}")
        
        # Ensure msd_values and lag_times have the same length
        min_length = min(len(avg_msd), len(lag_times))
        avg_msd = avg_msd[:min_length]
        lag_times = lag_times[:min_length]
        
        # Calculate diffusion coefficient and exponent using the average MSD
        diffusion_coeff, diffusion_exponent, fit_end_index = calculate_diffusion_coefficient(avg_msd, lag_times)
        if do_plot:
            visualize_msd_fit(avg_msd, lag_times, diffusion_coeff, diffusion_exponent, fit_end_index, d_name)
        return avg_msd, [diffusion_coeff], [diffusion_exponent]
    else:
        return None, None, None
def save_aggregated_data(all_results, directories, max_lag_time):
    """
    Save aggregated MSD data, diffusion coefficients, and exponents to an Excel file.
    Group headings are directory names from directory_names array, and subcolumns are files from that directory.
    """
    # Create DataFrames to hold MSD, diffusion coefficients, and exponents data
    msd_df = pd.DataFrame()
    diff_coeff_df = pd.DataFrame()
    exponents_df = pd.DataFrame()

    # Determine the maximum number of files across all directories
    max_file_count = max(len(results) for results in all_results)

    for directory, dir_name, results in zip(directories, directory_names, all_results):
        for idx in range(max_file_count):
            # Create a file name identifier based on index
            file_name = f"file_{idx+1}"
            
            if idx < len(results):
                result = results[idx]
                
                # Extract MSDs, diffusion coefficients, and exponents from the result
                msds = result['msd']
                diff_coeffs = result['diff_coeff']
                exponents = result['diff_exponent']
            else:
                # Pad with NaN if there are fewer files in the directory
                msds = [float('nan')]
                diff_coeffs = [float('nan')]
                exponents = [float('nan')]
            
            # Ensure that each result has the same number of rows by reindexing to the max length
            max_length = max(len(msds), len(diff_coeffs), len(exponents))
            msds = pd.Series(msds).reindex(range(max_length))
            diff_coeffs = pd.Series(diff_coeffs).reindex(range(max_length))
            exponents = pd.Series(exponents).reindex(range(max_length))
            
            # Add to DataFrame with a MultiIndex: (directory_name, file_name)
            msd_df[(dir_name, file_name)] = msds
            diff_coeff_df[(dir_name, file_name)] = diff_coeffs
            exponents_df[(dir_name, file_name)] = exponents

    # Convert the columns to MultiIndex
    msd_df.columns = pd.MultiIndex.from_tuples(msd_df.columns)
    diff_coeff_df.columns = pd.MultiIndex.from_tuples(diff_coeff_df.columns)
    exponents_df.columns = pd.MultiIndex.from_tuples(exponents_df.columns)

    # Save all DataFrames to an Excel file
    save_path = '/Volumes/Samsung_T5/Paper/Diffusion'
    if not os.path.exists(save_path):
        os.makedirs(save_path)

    excel_file_path = os.path.join(save_path, f'Aggregated_Diffusion_Data_{max_lag_time}.xlsx')
    
    # Write to Excel file with different sheets for each type of data
    with pd.ExcelWriter(excel_file_path, engine='xlsxwriter') as writer:
        msd_df.to_excel(writer, sheet_name='MSD Data')
        diff_coeff_df.to_excel(writer, sheet_name='Diffusion Coefficients')
        exponents_df.to_excel(writer, sheet_name='Exponents')

    print(f"Aggregated data saved to Excel: {excel_file_path}")

def save_diffusion_exponents(results, directory):
    """Save diffusion exponents to a CSV file."""
    exponent_data = {}
    for result in results:
        file_name = result['file_name']
        diffusion_exponents = result['diff_exponent']
        if diffusion_exponents:
            exponent_data[file_name] = diffusion_exponents

    exponent_df = pd.DataFrame.from_dict(exponent_data, orient='index').transpose()
    output_file = os.path.join(directory, 'Diffusion_Data', 'diffusion_exponents.csv')
    os.makedirs(os.path.dirname(output_file), exist_ok=True)
    exponent_df.to_csv(output_file, index=False)
    print(f"Diffusion exponents saved to {output_file}")


def save_diffusion_coefficients(results, directory):
    """Save diffusion coefficients to a CSV file."""
    diffusion_data = {}
    for result in results:
        file_name = result['file_name']
        diffusion_coeffs = result['diff_coeff']
        if diffusion_coeffs:
            diffusion_data[file_name] = diffusion_coeffs

    diffusion_df = pd.DataFrame.from_dict(diffusion_data, orient='index').transpose()
    output_file = os.path.join(directory, 'Diffusion_Data', 'diffusion_coefficients.csv')
    os.makedirs(os.path.dirname(output_file), exist_ok=True)
    diffusion_df.to_csv(output_file, index=False)
    print(f"Diffusion coefficients saved to {output_file}")

def analyze_directories(directories, max_lag_time):
    all_results = []

    for directory , directory_name in zip(directories, directory_names):
        print(f"Analyzing directory: {directory}")
        results = []

        for file_name in os.listdir(directory):
            if file_name.endswith(".csv") and not file_name.startswith('.'):
                file_path = os.path.join(directory, file_name)
                avg_msd, diff_coeff, diff_exponent = analyze_csv(file_path, max_lag_time, segment_duration, directory_name)

                if avg_msd is not None:
                    results.append({'file_name': file_name, 'msd': avg_msd, 'diff_coeff': diff_coeff, 'diff_exponent': diff_exponent})

        if results:
            all_results.append(results)
        else:
            print(f"No valid segments found in directory {directory}.")

    # Save aggregated data
    save_aggregated_data(all_results, directories, max_lag_time)


def save_msd_data_combined(results, max_lag_time, directory):
    """Save combined MSD data to a CSV file."""
    msd_df = pd.DataFrame()
    lag_times = np.arange(max_lag_time + 1)
    msd_df['Lag Time'] = lag_times

    for result in results:
        file_name = result['file_name']
        msd_values = result['msd']
        msd_df[file_name] = msd_values

    output_file = os.path.join(directory, 'Diffusion_Data', 'combined_msd_data.csv')
    os.makedirs(os.path.dirname(output_file), exist_ok=True)
    msd_df.to_csv(output_file, index=False)
    print(f"MSD data saved to {output_file}")

# Assuming 'directories' is defined elsewhere in your code
analyze_directories(directories, max_lag_time)




